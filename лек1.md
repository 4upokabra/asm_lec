## Системное программирование — Лекция 1

Конспект по теме: архитектура ЦПУ, системная шина, иерархия памяти (регистры — кэш — ОЗУ), когерентность кэшей, DMA, предвыборка и внеочередное исполнение. Исправлены очевидные огрехи распознавания речи.

### Ключевые тезисы
- **Системная шина**: разделяется концептуально на шину адреса, шину данных и шину управления/прерываний. Разрядность адресной шины определяет максимально адресуемый объём памяти.
- **Разрядность**: чаще связана с размером регистров общего назначения и шириной адресного пространства, но это условность: в системе существуют разные адресные пространства (эффективное/линейное/виртуальное/физическое).
- **Тактовая частота**: определяется физическими задержками в логике и длиной проводников; одна команда может занимать от 1 до сотен тактов.
- **Иерархия памяти**: регистры (очень быстро, очень мало) → кэш L1 (разделяют на I/D) → кэш L2 (на ядро) → кэш L3 (общий для всех ядер) → ОЗУ (медленнее, много).
- **Кэш**: ассоциативная память с фиксированными «кэш-строками» (cache line). Используются стратегии вытеснения (практически: разновидности LRU/Random), уровни ассоциативности (обычно 4–16‑way), политика записи часто отложенная (write‑back) с инвалидизацией.
- **Когерентность**: при записи в один кэш остальные должны увидеть консистентное состояние (инвалидируются/обновляются строки на других ядрах; протоколы уровня MESI/MOESI по сути).
- **DMA**: устройства ввода‑вывода могут писать/читать напрямую из ОЗУ, минуя ЦПУ, что требует управления когерентностью кэшей (инвалидировать/не кэшировать буферы).
- **Предвыборка и выравнивание**: предикторы подтягивают следующие кэш‑строки; невыравненные данные часто вызывают двойные обращения к памяти.
- **Внутренняя параллельность**: внеочередное исполнение (out‑of‑order), несколько исполнительных блоков; независимые инструкции выполняются, пока другие ждут память.

### Модель аппаратной платформы
```mermaid
graph LR
    %% Определение стилей
    classDef default fill:#fff,stroke:#333,stroke-width:2px
    classDef cpu fill:#f9f9f9,stroke:#666
    classDef core fill:#f5f5f5,stroke:#999
    
    %% Процессор и ядро
    subgraph CPU["ЦП (процессор)"]
        subgraph Core["Ядро"]
            REG["Регистры"]
            ALU["АЛУ/вычислители"]
            L1i["Кэш L1I<br/>(инструкции)"]
            L1d["Кэш L1D<br/>(данные)"]
            
            %% Связи внутри ядра
            REG --> ALU
            L1i --> ALU
            ALU --> L1d
        end
        L2["Кэш L2<br/>(на ядро)"]
    end
    
    %% Внешние компоненты
    L3["Кэш L3<br/>(общий для всех ядер)"]
    MEM["ОЗУ<br/>(DRAM)"]
    IO["Устройства<br/>ввода-вывода<br/>(DMA)"]
    
    %% Связи между компонентами
    L1d --> L2
    L2 --> L3
    L3 --> MEM
    IO -. "DMA" .-> MEM
    
    %% Применение стилей
    class CPU cpu
    class Core core
```

### Шины и разрядность
- **Шина адреса**: ширина в n бит задаёт потенциальный объём адресуемой памяти: 2^n байт. Примеры: 20 бит → 1 MiB (ранние x86), 32 бит → 4 GiB, 36 бит → 64 GiB, современные x86‑64 используют физические адреса порядка десятков бит (в лекции — «≈53 бита» как ориентир, что «хватает с большим запасом»).
- **Шина данных**: определяет, сколько данных можно передать за такт. Исторически 8/16 бит; затем 32/64 бита. Увеличение ширины повышает пропускную способность, но усложняет схемотехнику и энергопотребление.
- **Шина прерываний/управления**: сигналы рукопожатий, запросы прерываний и др.

Привязка «разрядности процессора» — условна: связана и с шириной регистров общего назначения, и с адресными пространствами, но внутри платформы сосуществуют разные ширины.

### Тактовая частота и синхронизация
- Тактовый генератор задаёт частоту работы узлов; задержки по проводникам и логике ограничивают максимум.
- Операции синхронизируются по фронтам такта; одни инструкции заканчиваются за 1–2 такта, другие ждут десятки/сотни тактов из‑за обращений в память.

### Иерархия памяти: размеры и скорость (порядки)
```mermaid
graph LR
    %% Определение стилей
    classDef default fill:#fff,stroke:#333,stroke-width:2px
    classDef memory fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    
    %% Узлы памяти
    REG["Регистры<br/>(очень быстро,<br/>очень мало)"]
    L1["Кэш L1<br/>(быстро,<br/>десятки-сотни КБ)"]
    L2["Кэш L2<br/>(медленнее,<br/>сотни КБ-1+ МБ)"]
    L3["Кэш L3<br/>(ещё медленнее,<br/>единицы-десятки МБ,<br/>общий)"]
    RAM["ОЗУ<br/>(намного медленнее,<br/>гигабайты)"]
    
    %% Связи
    REG --> L1
    L1 --> L2
    L2 --> L3
    L3 --> RAM
    
    %% Применение стилей
    class REG,L1,L2,L3,RAM memory

Замечания:
- L1 часто разделяют на кэш инструкций (L1I) и кэш данных (L1D), чтобы они не вытесняли друг друга.
- L2 обычно привязан к ядру; L3 — общий между ядрами.
- По площади на кристалле кэши занимают значимую долю, иногда больше, чем вычислительные блоки.

### Как работает кэш
- **Кэш‑строка (cache line)** — фиксированный блок памяти, минимальная единица обмена между ОЗУ и кэшем. На современных x86 обычно 64 байта; концептуально — «строка фиксированного размера».
- **Поиск**: ассоциативная память. Адрес разбивается на тэг/индекс/смещение. Уровень ассоциативности (n‑way) задаёт число позиций в наборе.
- **Промах (miss)**: при отсутствии строки запускается чтение из следующего уровня (L1→L2→L3→ОЗУ), затем строка размещается в кэше с возможным вытеснением.
- **Вытеснение**: на практике упрощённые эвристики (разновидности LRU/Random) из‑за аппаратных ограничений.
- **Запись**: часто используется write‑back (задержка записи в ОЗУ; строки помечаются «грязными»), с инвалидизацией у других ядер.

Последовательность обращения на чтение:
```mermaid
graph TD
    %% Определение стилей
    classDef default fill:#fff,stroke:#333,stroke-width:2px
    classDef decision fill:#f8f8f8,stroke:#666,stroke-width:2px
    classDef process fill:#e1f5fe,stroke:#0288d1,stroke-width:2px
    
    %% Узлы
    Start[("Запрос<br/>load addr")] --> B
    B{"Hit в L1?"}
    R1["Данные из L1<br/>→ CPU"]
    C{"Hit в L2?"}
    R2["Загрузить строку<br/>в L1 → CPU"]
    D{"Hit в L3?"}
    R3["L3 → L2 → L1<br/>→ CPU"]
    R4["DRAM → L3 → L2<br/>→ L1 → CPU"]
    
    %% Связи
    B -->|"Да"| R1
    B -->|"Нет"| C
    C -->|"Да"| R2
    C -->|"Нет"| D
    D -->|"Да"| R3
    D -->|"Нет"| R4
    
    %% Применение стилей
    class B,C,D decision
    class R1,R2,R3,R4 process
    class Start default
```

### Когерентность кэшей (многопоточность/многоядерность)
- При записи ядро помечает/инициирует обновление состояния соответствующей строки на других ядрах: чужие копии инвалидируются или переводятся в согласованное состояние.
- Широковещательные/точечные сообщения между ядрами ограничивают масштабируемость: стоимость растёт с числом ядер и объёмом кэшей.
- Гарантируется «минимум корректности» на уровне аппаратуры; строгая синхронизация порядка видимости данных — зона ответственности программы/ОС (барьеры памяти, блокировки, атомики).

### DMA и взаимодействие с кэшем
- Устройства могут читать/писать в ОЗУ напрямую (DMA), минуя ЦПУ. Это ускоряет ввод‑вывод и разгружает процессор.
- Опасность: кэши могут содержать устаревшие копии данных. Решения: использовать некэшируемые буферы; перед DMA‑чтением инвалидировать соответствующие линии; после DMA‑записи обеспечить видимость данных для ЦПУ (очистка/инвалидизация по адресам буферов).

### Предвыборка и выравнивание
- Аппаратная предвыборка подтягивает «следующие вероятные» кэш‑строки при обнаружении последовательных/шаблонных обращений.
- Невыравненные структуры данных (пересекающие границу кэш‑строки) вызывают дополнительные обращения к памяти. Практика: выравнивать структуры/буферы по размеру кэш‑строки.

### Внутренняя параллельность и внеочередное исполнение
- Современные ядра имеют несколько исполнительных устройств; независимые инструкции исполняются, пока другие ждут память.
- Переупорядочивание, переименование регистров и буферы переупорядочивания используют «скрытый» параллелизм.

Пример (независимая от памяти инструкция может идти вперёд):
```asm
mov bx, [ax] ; потенциально ждёт память
inc ax       ; может исполниться сразу (независима)
```

### Исторические/практические ориентиры (по лекции)
- Ранние x86: адресная шина 20 бит → 1 MiB, затем 24/32 бита; позже расширения до 36 бит (~64 GiB), современные физические адреса ещё шире.
- L1: десятки–сотни КБ на ядро (часто раздельно I/D). L2: сотни КБ–1+ МБ на ядро. L3: общий — единицы/десятки МБ.

### Что важно для программиста на низком уровне
- Учитывать локальность данных и кода; стараться работать с буферами, помещающимися в кэш L1/L2.
- Выравнивать горячие структуры и критические буферы по размеру кэш‑строки.
- Минимизировать ложное совместное использование (false sharing) между потоками (разнести горячие данные по разным кэш‑линиям).
- Для буферов DMA — использовать некэшируемые регионы или явно очищать/инвалидировать линии.
- В многопоточном коде — использовать барьеры памяти/атомики для корректной видимости данных.

---

Примечание: термины типа «проводки/проводочки» нормализованы до «линии шины/провода», «чипса» → «чипсет», «радость» → «адрес», «каши/каш» → «кэш», «памяти в спальне» → «в памяти/в регистрах», и т.п. по смыслу лекции.
