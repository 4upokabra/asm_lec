## Системное программирование — Лекция 1

Конспект по теме: архитектура ЦПУ, системная шина, иерархия памяти (регистры — кэш — ОЗУ), когерентность кэшей, DMA, предвыборка и внеочередное исполнение. Исправлены очевидные огрехи распознавания речи.

### Ключевые тезисы
- **Системная шина**: разделяется концептуально на шину адреса, шину данных и шину управления/прерываний. Разрядность адресной шины определяет максимально адресуемый объём памяти.
- **Разрядность**: чаще связана с размером регистров общего назначения и шириной адресного пространства, но это условность: в системе существуют разные адресные пространства (эффективное/линейное/виртуальное/физическое).
- **Тактовая частота**: определяется физическими задержками в логике и длиной проводников; одна команда может занимать от 1 до сотен тактов.
- **Иерархия памяти**: регистры (очень быстро, очень мало) → кэш L1 (разделяют на I/D) → кэш L2 (на ядро) → кэш L3 (общий для всех ядер) → ОЗУ (медленнее, много).
- **Кэш**: ассоциативная память с фиксированными «кэш-строками» (cache line). Используются стратегии вытеснения (практически: разновидности LRU/Random), уровни ассоциативности (обычно 4–16‑way), политика записи часто отложенная (write‑back) с инвалидизацией.
- **Когерентность**: при записи в один кэш остальные должны увидеть консистентное состояние (инвалидируются/обновляются строки на других ядрах; протоколы уровня MESI/MOESI по сути).
- **DMA**: устройства ввода‑вывода могут писать/читать напрямую из ОЗУ, минуя ЦПУ, что требует управления когерентностью кэшей (инвалидировать/не кэшировать буферы).
- **Предвыборка и выравнивание**: предикторы подтягивают следующие кэш‑строки; невыравненные данные часто вызывают двойные обращения к памяти.
- **Внутренняя параллельность**: внеочередное исполнение (out‑of‑order), несколько исполнительных блоков; независимые инструкции выполняются, пока другие ждут память.

### Модель аппаратной платформы
```mermaid
graph LR
  subgraph CPU["ЦП (процессор)"]
    subgraph Core1["Ядро"]
      REG["Регистры"]
      ALU["АЛУ/вычислители"]
      L1i["Кэш L1I (инструкции)"]
      L1d["Кэш L1D (данные)"]
      REG-->ALU
      L1i-->ALU
      ALU-->L1d
    end
    L2["Кэш L2 (на ядро)"]
  end
  L3["Кэш L3 (общий для всех ядер)"]
  MEM["ОЗУ (DRAM)"]
  IO["Устройства ввода-вывода (DMA)"]
  L1d-->L2
  L2-->L3
  L3-->MEM
  IO--"DMA"-->MEM
```

### Шины и разрядность
- **Шина адреса**: ширина в n бит задаёт потенциальный объём адресуемой памяти: 2^n байт. Примеры: 20 бит → 1 MiB (ранние x86), 32 бит → 4 GiB, 36 бит → 64 GiB, современные x86‑64 используют физические адреса порядка десятков бит (в лекции — «≈53 бита» как ориентир, что «хватает с большим запасом»).
- **Шина данных**: определяет, сколько данных можно передать за такт. Исторически 8/16 бит; затем 32/64 бита. Увеличение ширины повышает пропускную способность, но усложняет схемотехнику и энергопотребление.
- **Шина прерываний/управления**: сигналы рукопожатий, запросы прерываний и др.

Привязка «разрядности процессора» — условна: связана и с шириной регистров общего назначения, и с адресными пространствами, но внутри платформы сосуществуют разные ширины.

### Тактовая частота и синхронизация
- Тактовый генератор задаёт частоту работы узлов; задержки по проводникам и логике ограничивают максимум.
- Операции синхронизируются по фронтам такта; одни инструкции заканчиваются за 1–2 такта, другие ждут десятки/сотни тактов из‑за обращений в память.

### Иерархия памяти: размеры и скорость (порядки)
```mermaid
graph LR
  A["Регистры (очень быстро, очень мало)"] --> B["Кэш L1 (быстро, десятки–сотни КБ)"]
  B --> C["Кэш L2 (медленнее, сотни КБ–1+ МБ)"]
  C --> D["Кэш L3 (ещё медленнее, единицы–десятки МБ, общий)"]
  D --> E["ОЗУ (намного медленнее, гигабайты)"]
```

Замечания:
- L1 часто разделяют на кэш инструкций (L1I) и кэш данных (L1D), чтобы они не вытесняли друг друга.
- L2 обычно привязан к ядру; L3 — общий между ядрами.
- По площади на кристалле кэши занимают значимую долю, иногда больше, чем вычислительные блоки.

### Как работает кэш
- **Кэш‑строка (cache line)** — фиксированный блок памяти, минимальная единица обмена между ОЗУ и кэшем. На современных x86 обычно 64 байта; концептуально — «строка фиксированного размера».
- **Поиск**: ассоциативная память. Адрес разбивается на тэг/индекс/смещение. Уровень ассоциативности (n‑way) задаёт число позиций в наборе.
- **Промах (miss)**: при отсутствии строки запускается чтение из следующего уровня (L1→L2→L3→ОЗУ), затем строка размещается в кэше с возможным вытеснением.
- **Вытеснение**: на практике упрощённые эвристики (разновидности LRU/Random) из‑за аппаратных ограничений.
- **Запись**: часто используется write‑back (задержка записи в ОЗУ; строки помечаются «грязными»), с инвалидизацией у других ядер.

Последовательность обращения на чтение:
```mermaid
graph TD
  A["Запрос load [addr]"] --> B{Hit в L1?}
  B -- Да --> R1[Данные из L1 → CPU]
  B -- Нет --> C{Hit в L2?}
  C -- Да --> R2[Загрузить строку в L1 → отдать CPU]
  C -- Нет --> D{Hit в L3?}
  D -- Да --> R3[L3 → L2 → L1 → CPU]
  D -- Нет --> R4[DRAM → L3 → L2 → L1 → CPU]
```

### Когерентность кэшей (многопоточность/многоядерность)
- При записи ядро помечает/инициирует обновление состояния соответствующей строки на других ядрах: чужие копии инвалидируются или переводятся в согласованное состояние.
- Широковещательные/точечные сообщения между ядрами ограничивают масштабируемость: стоимость растёт с числом ядер и объёмом кэшей.
- Гарантируется «минимум корректности» на уровне аппаратуры; строгая синхронизация порядка видимости данных — зона ответственности программы/ОС (барьеры памяти, блокировки, атомики).

### DMA и взаимодействие с кэшем
- Устройства могут читать/писать в ОЗУ напрямую (DMA), минуя ЦПУ. Это ускоряет ввод‑вывод и разгружает процессор.
- Опасность: кэши могут содержать устаревшие копии данных. Решения: использовать некэшируемые буферы; перед DMA‑чтением инвалидировать соответствующие линии; после DMA‑записи обеспечить видимость данных для ЦПУ (очистка/инвалидизация по адресам буферов).

### Предвыборка и выравнивание
- Аппаратная предвыборка подтягивает «следующие вероятные» кэш‑строки при обнаружении последовательных/шаблонных обращений.
- Невыравненные структуры данных (пересекающие границу кэш‑строки) вызывают дополнительные обращения к памяти. Практика: выравнивать структуры/буферы по размеру кэш‑строки.

### Внутренняя параллельность и внеочередное исполнение
- Современные ядра имеют несколько исполнительных устройств; независимые инструкции исполняются, пока другие ждут память.
- Переупорядочивание, переименование регистров и буферы переупорядочивания используют «скрытый» параллелизм.

Пример (независимая от памяти инструкция может идти вперёд):
```asm
mov bx, [ax] ; потенциально ждёт память
inc ax       ; может исполниться сразу (независима)
```

### Исторические/практические ориентиры (по лекции)
- Ранние x86: адресная шина 20 бит → 1 MiB, затем 24/32 бита; позже расширения до 36 бит (~64 GiB), современные физические адреса ещё шире.
- L1: десятки–сотни КБ на ядро (часто раздельно I/D). L2: сотни КБ–1+ МБ на ядро. L3: общий — единицы/десятки МБ.

### Что важно для программиста на низком уровне
- Учитывать локальность данных и кода; стараться работать с буферами, помещающимися в кэш L1/L2.
- Выравнивать горячие структуры и критические буферы по размеру кэш‑строки.
- Минимизировать ложное совместное использование (false sharing) между потоками (разнести горячие данные по разным кэш‑линиям).
- Для буферов DMA — использовать некэшируемые регионы или явно очищать/инвалидировать линии.
- В многопоточном коде — использовать барьеры памяти/атомики для корректной видимости данных.

---

Примечание: термины типа «проводки/проводочки» нормализованы до «линии шины/провода», «чипса» → «чипсет», «радость» → «адрес», «каши/каш» → «кэш», «памяти в спальне» → «в памяти/в регистрах», и т.п. по смыслу лекции.


